{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e501591",
   "metadata": {},
   "source": [
    "## CSV Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddaecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "df1 = pd.read_csv(\"bootcamps.csv\")\n",
    "df2 = pd.read_csv(\"translate_programs.csv\")\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "merged_df.to_csv(\"tuwaiq_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ece55c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b332a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33041fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94520425",
   "metadata": {},
   "source": [
    "Combine and Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa62a10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ghada./nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"tuwaiq_data.csv\") \n",
    "\n",
    "# Combine the relevant fields\n",
    "combined_fields = ['Title', 'Description', 'Category', 'Scope', 'Goals', 'Features', 'Requirements']\n",
    "df['combined_text'] = df[combined_fields].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # remove stopwords\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['combined_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8238c",
   "metadata": {},
   "source": [
    "## BERT Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f1853",
   "metadata": {},
   "source": [
    "Bootcamp & Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51120d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootcamp Embeddings shape: (47, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert to string and clean nulls just to be safe\n",
    "df['cleaned_text'] = df['cleaned_text'].astype(str)\n",
    "\n",
    "# Encode all bootcamps at once\n",
    "bootcamp_embeddings = model.encode(df['cleaned_text'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Check shape\n",
    "print(\"Bootcamp Embeddings shape:\", np.array(bootcamp_embeddings).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0f430",
   "metadata": {},
   "source": [
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec7d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Embedding shape: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "cv_text = \"\"\"\n",
    "Name: Ameen Alrashid\n",
    "Email: ameen.alrashid@email.com\n",
    "Phone: +966-5XXXXXXX\n",
    "Location: Dammam, Saudi Arabia\n",
    "LinkedIn: linkedin.com/in/ameenalrashid\n",
    "GitHub: github.com/ameenalrashid\n",
    "\n",
    "Professional Summary:\n",
    "Cybersecurity analyst with a strong background in securing enterprise systems, performing risk assessments, and implementing defense strategies. Experienced in monitoring network activity, mitigating threats, and enhancing information security compliance. Passionate about protecting digital infrastructure and staying current with emerging security trends.\n",
    "\n",
    "Education:\n",
    "Bachelor of Science in Computer Science – Imam Abdulrahman Bin Faisal University\n",
    "Graduation: May 2024\n",
    "\n",
    "Certifications:\n",
    "- CompTIA Security+\n",
    "- Certified Ethical Hacker (CEH)\n",
    "- IBM Cybersecurity Analyst Professional Certificate\n",
    "\n",
    "Technical Skills:\n",
    "- Security Tools: Snort, Nmap, Nessus, Splunk\n",
    "- Languages: Python, PowerShell, JavaScript\n",
    "- Networking: TCP/IP, DNS, VPN, NAT, OSI Model\n",
    "- Platforms: Windows Server, Kali Linux, Ubuntu\n",
    "- Practices: Penetration Testing, SIEM, Incident Response, Threat Hunting\n",
    "\n",
    "Projects:\n",
    "Web App Penetration Testing Simulation\n",
    "- Identified and exploited OWASP Top 10 vulnerabilities in a test application\n",
    "- Documented flaws and provided remediation strategies\n",
    "- Demonstrated XSS, SQLi, and CSRF attacks in a live demo\n",
    "\n",
    "Security Information and Event Management (SIEM) Dashboard\n",
    "- Built custom SIEM dashboard using Splunk\n",
    "- Created real-time alerts for unusual login patterns and port scans\n",
    "- Reduced detection time for incidents by 40%\n",
    "\n",
    "Experience:\n",
    "Cybersecurity Intern – Aramco Cyber Defense Center\n",
    "Jul 2023 – Sep 2023\n",
    "- Conducted internal vulnerability scans and documented findings\n",
    "- Analyzed phishing attempts and contributed to monthly threat reports\n",
    "- Assisted in deploying endpoint detection and response (EDR) solutions\n",
    "\n",
    "Languages:\n",
    "- Arabic: Native\n",
    "- English: Professional Proficiency\n",
    "\n",
    "Interests:\n",
    "- Capture the Flag (CTF) challenges\n",
    "- Malware analysis\n",
    "- Threat intelligence platforms\n",
    "\n",
    "References:\n",
    "Available upon request\n",
    "\"\"\"\n",
    "\n",
    "# Result shape: (1, 384)\n",
    "cv_embedding = model.encode([cv_text])  \n",
    "\n",
    "print(\"CV Embedding shape:\", np.array(cv_embedding).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74bcbf",
   "metadata": {},
   "source": [
    "## BERT + Cosine Similarity Matching Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c1feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05a843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_embedding: shape (384,) → reshape to (1, 384)\n",
    "similarities = cosine_similarity(cv_embedding.reshape(1, -1), bootcamp_embeddings)\n",
    "\n",
    "# Get scores for each bootcamp\n",
    "similarities = similarities.flatten()\n",
    "\n",
    "# Rank bootcamps by similarity (highest first)\n",
    "top_indices = np.argsort(similarities)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92aa2881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Security+ Information Security (Score: 0.631)\n",
      "2. Cybersecurity (Score: 0.628)\n",
      "3. Cybersecurity Analyst CySA+ (Score: 0.605)\n",
      "4. Cybersecurity Fundamentals (Score: 0.603)\n",
      "5. Cybersecurity Defense L2 - SOC (Score: 0.586)\n"
     ]
    }
   ],
   "source": [
    "top_n = 5\n",
    "for i in range(top_n):\n",
    "    index = top_indices[i]\n",
    "    score = similarities[index]\n",
    "    title = df.iloc[index]['Title']\n",
    "    print(f\"{i+1}. {title} (Score: {score:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
