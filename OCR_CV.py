# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TlPlzMJf3Nz6RZbtbxgKnq3X3YJtMu1-
"""

import pytesseract
import re
from PIL import Image
import os
import json
import pdf2image
from pathlib import Path
from google.colab import files
import io

def extract_text_from_file(file_data, file_name):
    """Extract text from a file (PDF or image) using Tesseract OCR."""
    try:
        file_ext = Path(file_name).suffix.lower()

        if file_ext == '.pdf':
            # For PDF files, convert to images first
            print("Processing PDF file...")
            with open('temp.pdf', 'wb') as f:
                f.write(file_data)

            images = pdf2image.convert_from_path('temp.pdf')
            text = ""
            for i, img in enumerate(images):
                print(f"Processing page {i+1}/{len(images)}...")
                page_text = pytesseract.image_to_string(img)
                text += page_text + "\n\n"
            return text
        else:
            # For image files
            print("Processing image file...")
            img = Image.open(io.BytesIO(file_data))
            text = pytesseract.image_to_string(img)
            return text
    except Exception as e:
        print(f"Error extracting text from file: {e}")
        return None

def extract_contact_info(text):
    """Extract contact information from text."""
    contact_info = {}

    # Extract email
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    email_match = re.search(email_pattern, text)
    if email_match:
        contact_info['email'] = email_match.group()

    # Extract phone number (various formats)
    phone_pattern = r'(\+\d{1,3}[-.\s]?)?(\(?\d{3}\)?[-.\s]?)?\d{3}[-.\s]?\d{4}'
    phone_match = re.search(phone_pattern, text)
    if phone_match:
        contact_info['phone'] = phone_match.group().strip()

    # Extract LinkedIn profile
    linkedin_pattern = r'linkedin\.com/in/[A-Za-z0-9_-]+'
    linkedin_match = re.search(linkedin_pattern, text)
    if linkedin_match:
        contact_info['linkedin'] = linkedin_match.group()

    # Try to extract name (assume it's at the beginning of the resume)
    lines = text.strip().split('\n')
    non_empty_lines = [line for line in lines if line.strip()]
    if non_empty_lines:
        # Assume the first non-empty line is the name
        contact_info['name'] = non_empty_lines[0].strip()

    return contact_info

def extract_education(text):
    """Extract education information from text."""
    education = []

    # Look for education section
    education_section = None
    education_keywords = ['EDUCATION', 'Education', 'ACADEMIC BACKGROUND', 'Academic Background']

    for keyword in education_keywords:
        if keyword in text:
            parts = text.split(keyword, 1)
            if len(parts) > 1:
                education_section = parts[1]
                break

    if education_section:
        # Find degree patterns
        degree_patterns = [
            r'(?:Bachelor|Master|Ph\.D|MBA|B\.S\.|M\.S\.|B\.A\.|M\.A\.|B\.Tech|M\.Tech)[^\n]*',
            r'(?:University|College|Institute)[^\n]*'
        ]

        for pattern in degree_patterns:
            matches = re.findall(pattern, education_section)
            for match in matches:
                education.append(match.strip())

    return education

def extract_experience(text):
    """Extract work experience information from text."""
    experience = []

    # Look for experience section
    experience_section = None
    experience_keywords = ['EXPERIENCE', 'Experience', 'WORK EXPERIENCE', 'Work Experience', 'EMPLOYMENT', 'Employment']

    for keyword in experience_keywords:
        if keyword in text:
            parts = text.split(keyword, 1)
            if len(parts) > 1:
                experience_section = parts[1]
                break

    if experience_section:
        # Split by potential job entries (dates are good indicators)
        date_pattern = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\.?\s+\d{4}\s*(?:–|-|to)\s*(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December|Present|Current|Now)\.?\s*\d{0,4}'

        # Find all date ranges
        date_matches = re.finditer(date_pattern, experience_section)
        positions = [(m.start(), m.end()) for m in date_matches]

        # Extract job details based on these positions
        for i, (start, end) in enumerate(positions):
            if i < len(positions) - 1:
                job_text = experience_section[start:positions[i+1][0]]
            else:
                # For the last position, take till the next major section or end
                next_section = re.search(r'\n\s*(?:SKILLS|Skills|EDUCATION|Education|PROJECTS|Projects)', experience_section[end:])
                if next_section:
                    job_text = experience_section[start:end + next_section.start()]
                else:
                    job_text = experience_section[start:]

            experience.append(job_text.strip())

    return experience

def extract_skills(text):
    """Extract skills from text."""
    skills = []

    # Look for skills section
    skills_section = None
    skills_keywords = ['SKILLS', 'Skills', 'TECHNICAL SKILLS', 'Technical Skills']

    for keyword in skills_keywords:
        if keyword in text:
            parts = text.split(keyword, 1)
            if len(parts) > 1:
                skills_section = parts[1]
                break

    if skills_section:
        # Find the end of the skills section
        next_section = re.search(r'\n\s*(?:EXPERIENCE|Experience|EDUCATION|Education|PROJECTS|Projects|ACHIEVEMENTS|Achievements)', skills_section)
        if next_section:
            skills_section = skills_section[:next_section.start()]

        # Extract skills (look for comma-separated lists, bullet points, or new lines)
        skill_items = re.split(r',|\n|•|∙|·|\*', skills_section)
        for item in skill_items:
            clean_item = item.strip()
            if clean_item and len(clean_item) > 1:  # Avoid single characters
                skills.append(clean_item)

    return skills

def parse_resume(text):
    """Parse the resume text into structured information."""
    resume_data = {
        'contact_info': extract_contact_info(text),
        'education': extract_education(text),
        'experience': extract_experience(text),
        'skills': extract_skills(text)
    }

    return resume_data

# Upload a resume file (PDF or image)
uploaded = files.upload()

for file_name, file_data in uploaded.items():
    # Check file extension
    file_ext = Path(file_name).suffix.lower()
    supported_formats = ['.pdf', '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']

    if file_ext not in supported_formats:
        print(f"Error: Unsupported file format. Please use one of: {', '.join(supported_formats)}")
        continue

    # Extract text from file
    print(f"Processing resume: {file_name}")
    text = extract_text_from_file(file_data, file_name)

    if not text:
        print("Failed to extract text from the file.")
        continue

    # Save raw text for inspection
    with open('raw_text.txt', 'w', encoding='utf-8') as f:
        f.write(text)
    print("Raw extracted text saved to 'raw_text.txt'")

    # Parse the resume
    resume_data = parse_resume(text)

    # Print the extracted information
    print("\n==== Resume Information ====")

    # Contact Info
    print("\n--- Contact Information ---")
    for key, value in resume_data['contact_info'].items():
        print(f"{key.capitalize()}: {value}")

    # Education
    print("\n--- Education ---")
    for edu in resume_data['education']:
        print(f"• {edu}")

    # Experience
    print("\n--- Work Experience ---")
    for exp in resume_data['experience']:
        print(f"• {exp}")

    # Skills
    print("\n--- Skills ---")
    for skill in resume_data['skills']:
        print(f"• {skill}")

    # Save as JSON
    with open('resume_data.json', 'w') as f:
        json.dump(resume_data, f, indent=2)
    print("\nResume data saved to 'resume_data.json'")

    # Download the processed data files
    files.download('raw_text.txt')
    files.download('resume_data.json')